{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mip import *\n",
    "import networkx as nx\n",
    "import pickle\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The network\n",
    "g = nx.read_gml('networks/usa_99.gml', label=\"id\")\n",
    "L = len(g.edges)\n",
    "links = range(L)\n",
    "\n",
    "\n",
    "# The cut SRLGs\n",
    "with open ('min_cut_SRLGs/usa_99_10-4', 'rb') as fp:\n",
    "    cut_srlgs = pickle.load(fp)\n",
    "S = len(cut_srlgs)\n",
    "\n",
    "\n",
    "# The matrix of the intensity values, dimensions: [L,P,M] (link, position, magnitude)\n",
    "intensity = np.load('intensities/usa_99_ds23.npy')\n",
    "\n",
    "\n",
    "# The matrix of earthquake probabilities, dimensions: [P,M] (position, magnitude)\n",
    "prob_matrix = pd.read_csv('earthquake_probabilities/usa_ds23.csv').drop(['Lat', 'Long'], axis=1).to_numpy()\n",
    "P, M = prob_matrix.shape\n",
    "epicenters = range(P)\n",
    "magnitudes = range(M)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "Hnull = 6\n",
    "T = 0.01\n",
    "cost = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compressing the problem, to 1 SLRG and the minimum number of earthquakes\n",
    "cut_srlgs = cut_srlgs[:30]\n",
    "S = len(cut_srlgs)\n",
    "print(cut_srlgs)\n",
    "\n",
    "column_mask = np.full(intensity.shape[2], fill_value=False, dtype=bool)\n",
    "row_mask = np.full(intensity.shape[1], fill_value=False, dtype=bool)\n",
    "\n",
    "for srlg in cut_srlgs:\n",
    "    srlg_mask = np.full(intensity.shape[1:], fill_value=True, dtype=bool)\n",
    "    for link in srlg:\n",
    "        idx = list(g.edges).index(link)\n",
    "        print(idx, link, g.edges[link]['length'])\n",
    "        link_mask = intensity[idx]>6\n",
    "        srlg_mask &= link_mask\n",
    "    column_mask |= srlg_mask.any(axis=0)\n",
    "    row_mask |= srlg_mask.any(axis=1)\n",
    "\n",
    "intensity = intensity[:,:,column_mask][:,row_mask]\n",
    "prob_matrix = prob_matrix[:,column_mask][row_mask]\n",
    "\n",
    "P, M = prob_matrix.shape\n",
    "epicenters = range(P)\n",
    "magnitudes = range(M)\n",
    "\n",
    "print(f'The shape of the intensity matrix: {intensity.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3718"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srlg = cut_srlgs[2]\n",
    "edges = list(g.edges)\n",
    "link_mask = np.full(intensity.shape[1:], fill_value=True, dtype=bool)\n",
    "for l in srlg:\n",
    "    l_idx = edges.index(l)\n",
    "    link_mask &= intensity[l_idx] > H[l_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensity_tolerance = np.ones(L) * 6\n",
    "intensity[0] > intensity_tolerance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic 1 & 2\n",
    "\n",
    "def get_SRLG_probability_matrix(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix):\n",
    "    edges = list(network.edges)\n",
    "    srlg_occur = np.full(intensity_matrix.shape[1:], fill_value=True, dtype=bool)\n",
    "    for l in srlg:\n",
    "        l_idx = edges.index(l)\n",
    "        srlg_occur &= intensity[l_idx] > intensity_tolerance[l_idx]\n",
    "    return probability_matrix[srlg_occur]\n",
    "\n",
    "def remove_improbable_SRLGs(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    active_srlgs = srlgs.copy()\n",
    "    for s in active_srlgs.copy():\n",
    "        p = get_SRLG_probability_matrix(s, g, intensity, H, prob_matrix).sum()\n",
    "        if p < threshold:\n",
    "            active_srlgs.remove(s)\n",
    "    return active_srlgs\n",
    "\n",
    "def countSRLGlinks(srlgs, network):\n",
    "    edges = list(network.edges)\n",
    "    partofSRLG = np.zeros(len(edges), dtype=int)\n",
    "    for srlg in srlgs:\n",
    "        for l in srlg:\n",
    "            partofSRLG[edges.index(l)] += 1\n",
    "    #return dict(zip(edges, partofSRLG))\n",
    "    return partofSRLG\n",
    "\n",
    "def get_edge_to_improve_1(srlgs, network):\n",
    "    edges = list(network.edges)\n",
    "    partofSRLG = countSRLGlinks(srlgs, network)\n",
    "    max_indexes = [i for i, j in enumerate(partofSRLG) if j == max(partofSRLG)]\n",
    "    #print(max_indexes)\n",
    "    if len(max_indexes) > 1:\n",
    "        max_index = max_indexes[0]\n",
    "        min_length = network.edges[edges[max_index]]['length']\n",
    "        for idx in max_indexes:\n",
    "            length = network.edges[edges[idx]]['length']\n",
    "            if length < min_length:\n",
    "                max_index = idx\n",
    "                min_length = length\n",
    "        return max_index\n",
    "    else:\n",
    "        return max_indexes[0]\n",
    "\n",
    "def heuristic_1(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    active_srlgs = remove_improbable_SRLGs(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "    cost = 0\n",
    "    edges = list(network.edges)\n",
    "    print(len(active_srlgs))\n",
    "    while len(active_srlgs):\n",
    "        edge_to_improve = get_edge_to_improve_1(active_srlgs, network)\n",
    "        cost += network.edges[edges[edge_to_improve]]['length']\n",
    "        #print(edge_to_improve)\n",
    "        intensity_tolerance[edge_to_improve] += 1\n",
    "        active_srlgs = remove_improbable_SRLGs(active_srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "    print(f'H1 Cost: {cost:.0f}')\n",
    "    return intensity_tolerance, cost\n",
    "\n",
    "def get_SRLG_probability_reduction(link_idx, srlg, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    srlg_prob_matrix = get_SRLG_probability_matrix(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    srlg_prob = srlg_prob_matrix.sum()\n",
    "    intensity_tolerance[link_idx] += 1\n",
    "    new_srlg_prob_matrix= get_SRLG_probability_matrix(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    new_srlg_prob = new_srlg_prob_matrix.sum()\n",
    "    intensity_tolerance[link_idx] -= 1\n",
    "    return srlg_prob - new_srlg_prob\n",
    "\n",
    "def get_edge_to_improve_2(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    edges = list(network.edges)\n",
    "    probability_reduction_values = np.zeros(len(edges))\n",
    "    for idx, edge in enumerate(edges):\n",
    "        probability_reduction = 0\n",
    "        for srlg in srlgs:\n",
    "            if edge in srlg:\n",
    "                probability_reduction += get_SRLG_probability_reduction(idx, srlg, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "        probability_reduction_values[idx] = probability_reduction / network.edges[edge]['length']\n",
    "    return np.argmax(probability_reduction_values)\n",
    "\n",
    "def heuristic_2(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    active_srlgs = remove_improbable_SRLGs(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "    cost = 0\n",
    "    edges = list(network.edges)\n",
    "    print(len(active_srlgs))\n",
    "    while len(active_srlgs):\n",
    "        edge_to_improve = get_edge_to_improve_2(active_srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "        cost += network.edges[edges[edge_to_improve]]['length']\n",
    "        #print(edge_to_improve)\n",
    "        intensity_tolerance[edge_to_improve] += 1\n",
    "        active_srlgs = remove_improbable_SRLGs(active_srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "    print(f'H2 Cost: {cost:.0f}')\n",
    "    return intensity_tolerance, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SRLG_probability(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix):\n",
    "    edges = list(network.edges)\n",
    "    srlg_occur = np.full(intensity_matrix.shape[1:], fill_value=True, dtype=bool)\n",
    "    for l in srlg:\n",
    "        l_idx = edges.index(l)\n",
    "        srlg_occur &= intensity[l_idx] > intensity_tolerance[l_idx]\n",
    "    return probability_matrix[srlg_occur].sum()\n",
    "\n",
    "def get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix):\n",
    "    edges = list(network.edges)\n",
    "    cut_occur = np.full(intensity_matrix.shape[1:], fill_value=False, dtype=bool)\n",
    "    \n",
    "    for srlg in srlgs:\n",
    "        srlg_occur = np.full(intensity_matrix.shape[1:], fill_value=True, dtype=bool)\n",
    "        for l in srlg:\n",
    "            l_idx = edges.index(l)\n",
    "            srlg_occur &= intensity[l_idx] > intensity_tolerance[l_idx]\n",
    "        cut_occur |= srlg_occur\n",
    "    return probability_matrix[cut_occur].sum()\n",
    "\n",
    "def countSRLGlinks(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix):\n",
    "    edges = list(network.edges)\n",
    "    partofSRLG = np.zeros(len(edges), dtype=float)\n",
    "    for srlg in srlgs:\n",
    "        srlg_probability = get_SRLG_probability(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "        for l in srlg:\n",
    "            partofSRLG[edges.index(l)] += srlg_probability\n",
    "    #return dict(zip(edges, partofSRLG))\n",
    "    return partofSRLG\n",
    "\n",
    "def get_edge_to_improve_1(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix):\n",
    "    edges = list(network.edges)\n",
    "    partofSRLG = countSRLGlinks(srlg, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    partofSRLG = partofSRLG * (intensity_tolerance < 8.5)\n",
    "    max_indexes = [i for i, j in enumerate(partofSRLG) if j == max(partofSRLG)]\n",
    "    #print(max_indexes)\n",
    "    if len(max_indexes) > 1:\n",
    "        max_index = max_indexes[0]\n",
    "        min_length = network.edges[edges[max_index]]['length']\n",
    "        for idx in max_indexes:\n",
    "            length = network.edges[edges[idx]]['length']\n",
    "            if length < min_length:\n",
    "                max_index = idx\n",
    "                min_length = length\n",
    "        return max_index\n",
    "    else:\n",
    "        return max_indexes[0]\n",
    "\n",
    "def heuristic_1(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    active_srlgs = srlgs.copy()\n",
    "    edges = list(network.edges)\n",
    "    cost = 0\n",
    "    \n",
    "    probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    #print(f'{probability_of_falling_apart:.5f}')\n",
    "    \n",
    "    while probability_of_falling_apart > threshold:\n",
    "        edge_to_improve = get_edge_to_improve_1(active_srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "        cost += network.edges[edges[edge_to_improve]]['length']\n",
    "        #print(edge_to_improve)\n",
    "        intensity_tolerance[edge_to_improve] += 1\n",
    "        probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "        #print(f'{probability_of_falling_apart:.5f}')\n",
    "        #print(intensity_tolerance)\n",
    "        \n",
    "    print(f'H1 Cost: {cost:.0f}')\n",
    "    return intensity_tolerance, cost\n",
    "\n",
    "\n",
    "def get_edge_to_improve_2(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    edges = list(network.edges)\n",
    "    probability_reduction_values = np.zeros(len(edges))\n",
    "    probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    \n",
    "    for idx, edge in enumerate(edges):\n",
    "        probability_reduction = 0\n",
    "        if intensity_tolerance[idx] < 8.5:\n",
    "            intensity_tolerance[idx] += 1\n",
    "            decreased_probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "            probability_reduction = probability_of_falling_apart - max(threshold, decreased_probability_of_falling_apart)\n",
    "            intensity_tolerance[idx] -= 1\n",
    "        probability_reduction_values[idx] = probability_reduction / network.edges[edge]['length']\n",
    "    \n",
    "    return np.argmax(probability_reduction_values)\n",
    "\n",
    "def heuristic_2(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold):\n",
    "    active_srlgs = srlgs.copy()\n",
    "    edges = list(network.edges)\n",
    "    cost = 0\n",
    "    \n",
    "    probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "    #print(f'{probability_of_falling_apart:.5f}')\n",
    "    \n",
    "    while probability_of_falling_apart > threshold:\n",
    "        edge_to_improve = get_edge_to_improve_2(active_srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix, threshold)\n",
    "        cost += network.edges[edges[edge_to_improve]]['length']\n",
    "        #print(edge_to_improve)\n",
    "        intensity_tolerance[edge_to_improve] += 1\n",
    "        probability_of_falling_apart = get_probability_of_falling_apart(srlgs, network, intensity_matrix, intensity_tolerance, probability_matrix)\n",
    "        #print(f'{probability_of_falling_apart:.5f}')\n",
    "    \n",
    "    print(f'H2 Cost: {cost:.0f}')\n",
    "    return intensity_tolerance, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'T': [],\n",
    "    'SRLGs': [],\n",
    "    'Cost H1': [],\n",
    "    'Cost H2': [],\n",
    "    'Cost ILP': [],\n",
    "    'Runtime H1': [],\n",
    "    'Runtime H2': [],\n",
    "    'Runtime ILP': [],\n",
    "}\n",
    "\n",
    "upgraded_edges = {}\n",
    "spine_bonus = 0\n",
    "\n",
    "for idx,T in enumerate(np.concatenate((np.arange(0.01, 0.001, -0.001), np.arange(0.001, 0.0007, -0.0001)))):\n",
    "    print('\\n================')\n",
    "    print(f'T: {T:.4f}')\n",
    "    data['T'].append(T)\n",
    "    \n",
    "    data['SRLGs'].append(len(cut_srlgs))\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    H = np.ones(L) * 6\n",
    "    for i, e in enumerate(g.edges):\n",
    "        if g.edges[e]['onspine']:\n",
    "            H[i] += spine_bonus\n",
    "    H1, cost_1 = heuristic_1(cut_srlgs, g, intensity, H, prob_matrix, T)\n",
    "    runtime_1 = time.perf_counter() - start\n",
    "    data['Cost H1'].append(cost_1)\n",
    "    data['Runtime H1'].append(runtime_1)\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    H = np.ones(L) * 6\n",
    "    for i, e in enumerate(g.edges):\n",
    "        if g.edges[e]['onspine']:\n",
    "            H[i] += spine_bonus\n",
    "    H2, cost_2 = heuristic_2(cut_srlgs, g, intensity, H, prob_matrix, T)\n",
    "    runtime_2 = time.perf_counter() - start\n",
    "    data['Cost H2'].append(cost_2)\n",
    "    data['Runtime H2'].append(runtime_2)\n",
    "    \n",
    "    data['Cost ILP'].append(np.nan)\n",
    "    data['Runtime ILP'].append(np.nan)\n",
    "    \n",
    "    H = np.ones(L) * 6\n",
    "    for i, e in enumerate(g.edges):\n",
    "        if g.edges[e]['onspine']:\n",
    "            H[i] += spine_bonus\n",
    "    upgrade_1, upgrade_2 = [],[]\n",
    "    for l,e in enumerate(g.edges):\n",
    "        if H1[l] > H[l]:\n",
    "            upgrade_1.append((e,int(H1[l]-6)))\n",
    "        if H2[l] > H[l]:\n",
    "            upgrade_2.append((e,int(H2[l]-6)))\n",
    "    \n",
    "    upgraded_edges[idx] = {}\n",
    "    upgraded_edges[idx]['Upgrade H1'] = upgrade_1\n",
    "    upgraded_edges[idx]['Upgrade H2'] = upgrade_2\n",
    "\n",
    "    print('\\n================')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).to_csv('results/Heuristic_comparison_usa_99_nospine.csv', index=False, float_format='%.4f')\n",
    "with open('results/Heuristic_upgraded_edges_usa_99_nospine', 'wb') as fp:\n",
    "    pickle.dump(upgraded_edges, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.5 s:\tVáltozók létrehozva...\n",
      "58.6 s:\tCélfüggvény létrehozva...\n",
      "341.5 s:\tElső egyenlet létrehozva...\n",
      "631.1 s:\tMásodik egyenlet létrehozva...\n",
      "651.9 s:\tHarmadik egyenlet létrehozva...\n",
      "685.5 s:\tMegoldás megtalálva...\n"
     ]
    }
   ],
   "source": [
    "# ILP\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "#Model\n",
    "model = Model(sense=MINIMIZE, solver_name=GRB)\n",
    "\n",
    "#Variables\n",
    "deltaH = [model.add_var(var_type=INTEGER, lb=0, ub=3) for l,_ in enumerate(g.edges)]\n",
    "Z = [[[model.add_var(var_type=BINARY) for k in magnitudes] for j in epicenters] for i in range(S)]\n",
    "Y = [[[model.add_var(var_type=BINARY) for k in magnitudes] for j in epicenters] for i in links]\n",
    "W = [[model.add_var(var_type=BINARY) for k in magnitudes] for j in epicenters]\n",
    "print(\"%.1f s:\\tVáltozók létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "\n",
    "#Objective Function\n",
    "model.objective = xsum( g.edges[link_id]['length'] * deltaH[link_idx] for link_idx,link_id in enumerate(g.edges) )\n",
    "print(\"%.1f s:\\tCélfüggvény létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "\n",
    "#Constraint 1\n",
    "for l,p,m in product(*[links, epicenters, magnitudes]):\n",
    "    model.add_constr( Y[l][p][m] >= 1 - ((Hnull + deltaH[l]) / intensity[l,p,m]) )\n",
    "print(\"%.1f s:\\tElső egyenlet létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "\n",
    "#Constraint 2\n",
    "for (c,s), p, m in product(*[enumerate(cut_srlgs), epicenters, magnitudes]):\n",
    "    model.add_constr( Z[c][p][m] >= (xsum(Y[list(g.edges).index(linkID)][p][m] for linkID in s) - len(s) + 1) )\n",
    "print(\"%.1f s:\\tMásodik egyenlet létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "# #Constraint 3\n",
    "# for c,_ in enumerate(cut_srlgs):\n",
    "#     model.add_constr(xsum( Z[c][p][m] * prob_matrix[p,m] for p,m in product(epicenters,magnitudes) ) <= T, \"c3_\"+str(c))\n",
    "# print(\"%.1f s:\\tHarmadik egyenlet létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "for (c,s), p, m in product(*[enumerate(cut_srlgs), epicenters, magnitudes]):\n",
    "    model.add_constr( W[p][m] >= Z[c][p][m] )\n",
    "\n",
    "#Constraint 3\n",
    "model.add_constr(xsum( W[p][m] * prob_matrix[p,m] for p,m in product(epicenters,magnitudes) ) <= T )\n",
    "print(\"%.1f s:\\tHarmadik egyenlet létrehozva...\"%(time.perf_counter()-start))\n",
    "\n",
    "#Start optimization\n",
    "model.optimize()#max_seconds=\n",
    "print(\"%.1f s:\\tMegoldás megtalálva...\"%(time.perf_counter()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The probability of occurance of the SRLGs\n",
    "for c,s in enumerate(cut_srlgs):\n",
    "    print(s, sum(Z[c][p][m].x * prob_matrix[p,m] for p,m in product(epicenters,magnitudes) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, (22, 24, 0), 379.1998052904187)\n",
      "(2.0, (23, 24, 0), 544.9774670804052)\n",
      "(1.0, (23, 25, 0), 1091.9747459465025)\n"
     ]
    }
   ],
   "source": [
    "# The result\n",
    "selected = [(deltaH[l].x,e, g.edges[e]['length']) for l,e in enumerate(g.edges) if deltaH[l].x >= 0.5]\n",
    "print(*selected, sep='\\n')\n",
    "#print([dH.x for dH in deltaH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional constraint\n",
    "# It does not deletes Constraint 3 but completes it\n",
    "for c,s in enumerate(cut_srlgs):\n",
    "    model.add_constr(xsum( Z[c][p][m] * prob_matrix[p,m] for p,m in product(epicenters,magnitudes) ) <= 0.00001, \"c3_\"+str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OptimizationStatus.OPTIMAL: 0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start optimization\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff(a,b):\n",
    "    return a*2 + b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected items: [3, 6]\n"
     ]
    }
   ],
   "source": [
    "#koltseg =  [11, 3,3, 6, 1, 9, 16,78]\n",
    "koltseg = 8\n",
    "fejlesztes = [17,6,4,61,16,42,156, 7]\n",
    "\n",
    "y = [1,1,0,1,0,1,0,0]\n",
    "z = [0,1,1,1,0,1,0,1]\n",
    "\n",
    "items = len(fejlesztes)\n",
    "\n",
    "m = Model(\"fradir\")\n",
    "\n",
    "#decision variable\n",
    "x = [m.add_var(var_type=BINARY) for i in range(items)]\n",
    "fejlesztes_Dvar = [m.add_var(var_type=INTEGER, lb=1, ub=6) for i in range(items)]\n",
    "\n",
    "#objective\n",
    "m.objective = maximize(xsum(koltseg * fejlesztes[i] * x[i] for i in range(items)))\n",
    "\n",
    "#cons\n",
    "#m += xsum(y[i] * x[i] for i in range(items)) >= 2\n",
    "\n",
    "#m += xsum(z[i] * x[i] for i in range(items)) >= 2\n",
    "\n",
    "#m += xsum(((y[i] + z[i]) % 2) * x[i]  for i in range(items)) == 0\n",
    "\n",
    "for i in range(items):\n",
    "    m += 10 * x[i] <= fejlesztes[i]\n",
    "\n",
    "#m += xsum(( fejlesztes[i] * x[i]  for i in range(items))) <= 14\n",
    "\n",
    "m += xsum(x[i] for i in range(items)) == 2\n",
    "\n",
    "\n",
    "m.optimize()\n",
    "\n",
    "selected = [i for i in range(items) if x[i].x >= 0.99]\n",
    "print(\"selected items: {}\".format(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEKKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from gekko import GEKKO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0] [0.0] [0.0] [0.0] [0.0] [0.0] [1.0] [0.0]]\n",
      "Sorszam: 6., koltseg: 16, fejlesztes: 6.0\n"
     ]
    }
   ],
   "source": [
    "koltseg =  [11, 3,3, 6, 1, 9, 16,78]\n",
    "fejlesztes = [17,67,4,61,16,42,156, 7]\n",
    "\n",
    "y = [1,0,1,1,0,1,1,0]\n",
    "z = [0,1,1,1,0,1,1,1]\n",
    "\n",
    "prob = [0.5, 1.2, 1.5, 1.7, 0.1, 1.8, 0.4, 1.9]\n",
    "\n",
    "items = len(koltseg)\n",
    "\n",
    "# Create model\n",
    "m = GEKKO()\n",
    "\n",
    "# Variables\n",
    "x = m.Array(m.Var,items,lb=0,ub=1,integer=True)\n",
    "fejlesztes_Dvar = m.Array(m.Var, items, lb=1,ub=6, integer=True)\n",
    "b = m.Array(m.Var, items, lb=1,ub=8, integer=True)\n",
    "#x2 = m.Array(m.Var, len(w),lb=0,ub=1,integer = True)\n",
    "\n",
    "# Objective\n",
    "m.Maximize(sum(koltseg[i] * fejlesztes_Dvar[i] * x[i] for i in range(items) ))\n",
    "\n",
    "# Constraint\n",
    "m.Equation(sum([(y[i] + z[i]) * x[i] for i in range(items)]) == 2)\n",
    "\n",
    "m.Equation(sum([x[i] for i in range(items)]) == 1)\n",
    "\n",
    "m.Equation(sum((z[i] * prob[i]) *x[i] for i in range(items)) <=1.6 )\n",
    "\n",
    "# Optimize with APOPT\n",
    "m.options.SOLVER = 1\n",
    "\n",
    "m.solve(disp = False)\n",
    "\n",
    "# Print the value of the variables at the optimum\n",
    "print(x)\n",
    "for i in range(len(x)):\n",
    "    if x[i][0] == 1.0:\n",
    "        print(\"Sorszam: {}., koltseg: {}, fejlesztes: {}\".format(i,koltseg[i], fejlesztes_Dvar[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('italy.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "      <td>48442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.154713</td>\n",
       "      <td>1.174508</td>\n",
       "      <td>1.196344</td>\n",
       "      <td>1.220365</td>\n",
       "      <td>1.246715</td>\n",
       "      <td>1.275495</td>\n",
       "      <td>1.306710</td>\n",
       "      <td>1.340423</td>\n",
       "      <td>1.376788</td>\n",
       "      <td>1.415944</td>\n",
       "      <td>...</td>\n",
       "      <td>3.194826</td>\n",
       "      <td>3.325022</td>\n",
       "      <td>3.459114</td>\n",
       "      <td>3.597036</td>\n",
       "      <td>3.738632</td>\n",
       "      <td>3.883800</td>\n",
       "      <td>4.032280</td>\n",
       "      <td>4.183553</td>\n",
       "      <td>4.337154</td>\n",
       "      <td>4.492752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.578387</td>\n",
       "      <td>0.617518</td>\n",
       "      <td>0.658248</td>\n",
       "      <td>0.700550</td>\n",
       "      <td>0.744388</td>\n",
       "      <td>0.789728</td>\n",
       "      <td>0.836545</td>\n",
       "      <td>0.884773</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.985046</td>\n",
       "      <td>...</td>\n",
       "      <td>2.112041</td>\n",
       "      <td>2.145883</td>\n",
       "      <td>2.176857</td>\n",
       "      <td>2.204735</td>\n",
       "      <td>2.229386</td>\n",
       "      <td>2.250615</td>\n",
       "      <td>2.268428</td>\n",
       "      <td>2.283199</td>\n",
       "      <td>2.295290</td>\n",
       "      <td>2.304934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.260501</td>\n",
       "      <td>1.422601</td>\n",
       "      <td>1.584701</td>\n",
       "      <td>1.746801</td>\n",
       "      <td>1.908901</td>\n",
       "      <td>2.071001</td>\n",
       "      <td>2.233101</td>\n",
       "      <td>2.395201</td>\n",
       "      <td>2.557301</td>\n",
       "      <td>2.719401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.691067</td>\n",
       "      <td>2.853167</td>\n",
       "      <td>3.015267</td>\n",
       "      <td>3.177367</td>\n",
       "      <td>3.339467</td>\n",
       "      <td>3.501567</td>\n",
       "      <td>3.663667</td>\n",
       "      <td>3.825767</td>\n",
       "      <td>3.987867</td>\n",
       "      <td>4.149967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.004125</td>\n",
       "      <td>...</td>\n",
       "      <td>4.570325</td>\n",
       "      <td>4.732425</td>\n",
       "      <td>4.894525</td>\n",
       "      <td>5.056625</td>\n",
       "      <td>5.218725</td>\n",
       "      <td>5.380825</td>\n",
       "      <td>5.542925</td>\n",
       "      <td>5.705025</td>\n",
       "      <td>5.867125</td>\n",
       "      <td>6.029225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.113586</td>\n",
       "      <td>6.275686</td>\n",
       "      <td>6.437786</td>\n",
       "      <td>6.599886</td>\n",
       "      <td>6.761986</td>\n",
       "      <td>6.924086</td>\n",
       "      <td>7.086186</td>\n",
       "      <td>7.248286</td>\n",
       "      <td>7.410386</td>\n",
       "      <td>7.572486</td>\n",
       "      <td>...</td>\n",
       "      <td>11.138686</td>\n",
       "      <td>11.300786</td>\n",
       "      <td>11.462886</td>\n",
       "      <td>11.624986</td>\n",
       "      <td>11.787086</td>\n",
       "      <td>11.949186</td>\n",
       "      <td>12.111286</td>\n",
       "      <td>12.273386</td>\n",
       "      <td>12.435486</td>\n",
       "      <td>12.597586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  48442.000000  48442.000000  48442.000000  48442.000000  48442.000000   \n",
       "mean       1.154713      1.174508      1.196344      1.220365      1.246715   \n",
       "std        0.578387      0.617518      0.658248      0.700550      0.744388   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "max        6.113586      6.275686      6.437786      6.599886      6.761986   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  48442.000000  48442.000000  48442.000000  48442.000000  48442.000000   \n",
       "mean       1.275495      1.306710      1.340423      1.376788      1.415944   \n",
       "std        0.789728      0.836545      0.884773      0.934307      0.985046   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "50%        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      1.004125   \n",
       "max        6.924086      7.086186      7.248286      7.410386      7.572486   \n",
       "\n",
       "       ...            31            32            33            34  \\\n",
       "count  ...  48442.000000  48442.000000  48442.000000  48442.000000   \n",
       "mean   ...      3.194826      3.325022      3.459114      3.597036   \n",
       "std    ...      2.112041      2.145883      2.176857      2.204735   \n",
       "min    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "25%    ...      1.260501      1.422601      1.584701      1.746801   \n",
       "50%    ...      2.691067      2.853167      3.015267      3.177367   \n",
       "75%    ...      4.570325      4.732425      4.894525      5.056625   \n",
       "max    ...     11.138686     11.300786     11.462886     11.624986   \n",
       "\n",
       "                 35            36            37            38            39  \\\n",
       "count  48442.000000  48442.000000  48442.000000  48442.000000  48442.000000   \n",
       "mean       3.738632      3.883800      4.032280      4.183553      4.337154   \n",
       "std        2.229386      2.250615      2.268428      2.283199      2.295290   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.908901      2.071001      2.233101      2.395201      2.557301   \n",
       "50%        3.339467      3.501567      3.663667      3.825767      3.987867   \n",
       "75%        5.218725      5.380825      5.542925      5.705025      5.867125   \n",
       "max       11.787086     11.949186     12.111286     12.273386     12.435486   \n",
       "\n",
       "                 40  \n",
       "count  48442.000000  \n",
       "mean       4.492752  \n",
       "std        2.304934  \n",
       "min        1.000000  \n",
       "25%        2.719401  \n",
       "50%        4.149967  \n",
       "75%        6.029225  \n",
       "max       12.597586  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data[0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
